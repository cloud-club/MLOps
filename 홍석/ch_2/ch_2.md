# [Week - 3]

<br>
### 쿠베플로우 : ML 워크플로우에 필요한 컴포넌트로 이루어진 툴킷

(주피터 노트북 서버, 카티브, 파이프라인)

대쉬보드 : 각 컴포넌트의 UI를 접근할 수 있는 게이트웨이 : 쿠베플로우의 컴포넌트들의 엔드포인트로 접근할 수 있다

(주피터 노트북 서버, 카티브, 파이프라인, artifact store, manage contributor)

<br>

### 로컬에서 대쉬보드 접속하기

kubectl 사용해 포트 포워딩으로 로컬호스트 주소로 대쉬보드 접근 가능

<br>

## Notebook Servers

쿠버네티스는 리소스를 스케줄링하기 때문에 노트북 설정만으로 간단히 노트북 할당 받을 수 있다.

- 다른 컴포넌트들이 제공하는 파이선 라이브러리를 가지고 노트북상에서 쿠베플로우의 대부분 컴포넌트를 사용할 수 있다
- 네임스페이스 별로 격리 되어 있어서 작업공간을 별도로 사용할 수 있다
  <br>

## Fairing

페어링은 쿠베플로우가 설치된 환경에서 손쉽게 ML 모델을 학습/배포 할 수 있는 파이썬 패키지

- 쉬운 ML 모델 트레이닝 잡 패키징 : 작성한 모델 코드를 도커화
- 쉬운 학습 : 클라우드에서 트레이닝 잡을 실행시킬 수 있는 고차원 API 지원으로 인해 클라우드 인프라스터럭처에 대한 깊은 지식이 필요 없음
- 쉬운 배포 : 고차원 API 지원으로 인해 학습된 모델의 배포를 쉽게 만듦

<br>

### 아키텍처

페어링은 쥬피터 노트북, 파이선 함수, 파이선 파일을 도커 이미지로 빌드

이미지가 빌드 되면 설정한 도커 레지스트리에 푸시

- preprocessor : 작성된 코드를 도커이미지에 넣을 수 있도록 패키지화
- Builder : 패키지된 파일을 도커 이미지화
- deployer : 생성된 이미지를 쿠버네티스 클러스터에 배포

<br>

## Katib (하이퍼파리미터 최적화 + 뉴럴아키텍처 탐색)

<br>

### 하이퍼파리미터 최적화

하이퍼파라미터 : 모델 학습과정을 컨트롤하는 변수

(사용자가 입력하는 값, 학습되는 값이 아니라 모델 성능을 영향을 주는 값)

카티브는 하이퍼 파라미터 선택을 검색 알고리즘에 따라 자동 수행 → 설정한 최적값이 나올 때까지 계속 반복함으로써 수동으로 진행했던 과정들을 자동화 시켜 준다

### 뉴럴 아키텍처 탐색

높은 예측 정확도의 최적 성능을 내는 인공신경망을 디자인 하기 위해 사용

### 아키텍처

카티프는 크게 4가지 개념으로 이루어져있다

1. Experiment : 하나의 최적화 실행단위
2. Trial : 최적화 과정의 반복 단위
3. Suggestion : 쿠버네티스 Custom Resource이며 검색 알고리즘을 통해 생성된 파라미터값의 모음
4. Worker Job : Parameter와 Suggestion 값을 가지고 Trial을 평가하며 목푯값을 계산하는 프로세스

## Pipeline

쿠베플로우 파이프라인 컨테이너 기반의 end-to-end ML 워크플로우를 만들고 배포할 수 있는 쿠버네티스 플랫폼

쿠버네티스의 자원을 관리하기 위해서 백엔드 프레임워크로 argo 워크플로우 툴을 사용

쿠베플로우 파이프라인

- 실험, 잡, 런 을 추적하고 관리하는 유저 인터페이스
- ML 워크플로우 단계별 스케쥴링 엔진
- 파이프라인과 그 컴포넌트들을 생성하는 SDK
- SDK와 연동하는 쥬피터 노트북

<aside>
💡 쉬운 파이프라인 구성
쉬운 파이프라인 생성
쉬운 재사용

</aside>

<br>

### 파이프라인

파이프라인은 워크플로의 컴포넌트들과 그것을 그래프 형태로 결합하는 것을 포함한 ML 워크플로우의 한 형식

파이프라인 실행되면 시스템은 각 단계에 맞는 쿠버네티스 파드 실행 → 설정된 컨테이너 실행 → 애플리케이션 실행 (스케줄러에 따라서 순서대로 컨테이너 실행)

<br>

### 컴포넌트

컴포넌트는 ML 워크플로우의 한 단계 수행하는 코드 집합

<br>

## Metadata

메타데이터 : 실행, 모델, 데이터셋, 아티팩트 정보

아티팩트 : ML 워크플로우에서 컴포넌트들의 입 출력을 구성하는 파일과 오브젝트

ML 워크플로우가 생성하는 메타데이터를 추적하고 관리함으로써 ML 워크플로우를 이해하고 관리할 수 있게 도와준다
