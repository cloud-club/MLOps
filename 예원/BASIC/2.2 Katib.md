# 🎨 Katib

하이퍼파라미터 최적화 / 뉴럴 아키텍처 탐색을 위한 컴포넌트

1.  하이퍼파라미터 최적화

사용자가 입력하는 값인 하이퍼파라미터 (LR, Dropout, layer, cost func .. ) 값들이 모델의 성능을 좌우함. 실제로 hyperparameter 최적화가 전체 ML workflow 에서 많은 시간을 차지하기 때문에 자동화가 필요!


2. 뉴럴 아키텍처 탐색

AutoML의 하나, 높은 정확도와 성능을 내는 NN 을 디자인하기 위해 사용됨. 
(카티브의 NAS 는 강화 학습을 선택)

## 아키텍처

![image](https://user-images.githubusercontent.com/77239220/226414635-b40875be-465c-46f3-83e0-080ed442ca46.png)

1. Experiment : 하나의 최적화 실행단위, 하나의 Job. Trial 을 실행함.
    
    - Trial Count; 실행 횟수, 병렬 실행 횟수
    - Trial Template; trial 파드 명세
    - Objective; goal, max, min
    - Search Parameter; 탐색하려는 파라미터, 값의 범위
    - Search Algorithm

2. Trial : 최적화 과정의 반복 단위. Experiment 의 Trial Count 수만큼 생성됨.

3. Suggestion : 검색 알고리즘을 통해 생성된 하이퍼 파라미터=값의 모음. 하나의 Experiment당 하나의 Suggestion이 생성되고 Experiment에서 설정된 Paramaeter과 검색 알고리즘이 낸 Value를 각 Trial에 제공 !

4. Worker Job : Parameter와 Suggestion 값을 가지고 Trial을 평가하며 목표값을 계산하는 프로세스. 실제로 학습을 수행하는 일을 하며, 단일 실행인 쿠버네티스 잡과 분산 실행이 가능한 텐서플로우 TFJob, 쿠베플로우 Pytorch 사용 가능.

